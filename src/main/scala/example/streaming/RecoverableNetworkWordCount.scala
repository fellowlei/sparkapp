package example.streaming

import java.io.File
import java.nio.charset.Charset

import com.google.common.io.Files
import org.apache.spark.{SparkConf, SparkContext}
import org.apache.spark.broadcast.Broadcast
import org.apache.spark.rdd.RDD
import org.apache.spark.streaming._
import org.apache.spark.util.LongAccumulator

/**
  * Created by lulei on 2018/3/21.
  */
object RecoverableNetworkWordCount {

  val checkpointDirectory="checkpointDir"

  def main(args: Array[String]): Unit = {
    val ssc = StreamingContext.getOrCreate(checkpointDirectory,
      () => createContext())
    ssc.start()
    ssc.awaitTermination()
  }
    def createContext():StreamingContext = {

      val ip = "localhost"
      val port = 8888
      val outputPath = "output"

      println("Creating new context")
      val outputFile = new File(outputPath)
      if(outputFile.exists()) outputFile.delete()

      val sparkConf =new SparkConf().setAppName("RecoverableNetworkWordCount")

      // Create the context with a 1 second batch size
      val ssc = new StreamingContext(sparkConf,Seconds(1))

      ssc.checkpoint(checkpointDirectory)

      // Create a socket stream on target ip:port and count the
      // words in input stream of \n delimited text (eg. generated by 'nc')
      val lines = ssc.socketTextStream(ip,port)
      val words = lines.flatMap(_.split(" "))
      val wordCounts = words.map((_,1)).reduceByKey(_ + _)

      wordCounts.foreachRDD { (rdd: RDD[(String, Int)], time: Time) =>
        // Get or register the blacklist Broadcast
        val blacklist = WordBlacklist.getInstance(rdd.sparkContext)
        // Get or register the droppedWordsCounter Accumulator
        val droppedWordsCounter = DroppedWordsCounter.getInstance(rdd.sparkContext)
        // Use blacklist to drop words and use droppedWordsCounter to count them
        val counts = rdd.filter { case (word, count) =>
          if (blacklist.value.contains(word)) {
            droppedWordsCounter.add(count)
            false
          } else {
            true
          }
        }.collect().mkString("[", ", ", "]")
        val output = s"Counts at time $time $counts"
        println(output)
        println(s"Dropped ${droppedWordsCounter.value} word(s) totally")
        println(s"Appending to ${outputFile.getAbsolutePath}")
        Files.append(output + "\n", outputFile, Charset.defaultCharset())
      }

      ssc
    }

  /**
    * Use this singleton to get or register a Broadcast variable.
    */
  object WordBlacklist {
    @volatile private var instance: Broadcast[Seq[String]] = null
    def getInstance(sc: SparkContext): Broadcast[Seq[String]] = {
      if (instance == null) {
        synchronized {
          if (instance == null) {
            val wordBlacklist = Seq("a", "b", "c")
            instance = sc.broadcast(wordBlacklist)
          }
        }
      }
      instance
    }
  }

  /**
    * Use this singleton to get or register an Accumulator.
    */
  object DroppedWordsCounter {
    @volatile private var instance: LongAccumulator = null
    def getInstance(sc: SparkContext): LongAccumulator = {
      if (instance == null) {
        synchronized {
          if (instance == null) {
            instance = sc.longAccumulator("WordsInBlacklistCounter")
          }
        }
      }
      instance
    }
  }
}
